% ==============================================================================
% CHAPTER 31: Hamming Distance & Error Detection
% ==============================================================================

\chapter{Hamming Distance \& Error Detection}
\label{ch:hamming-distance}

\begin{nontechnical}
    \textbf{Hamming distance is like counting the number of spelling differences between two words of the same length.} The more letters that differ, the "further apart" the words are.
    
    \parhead{A simple comparison}
    \begin{itemize}
        \item \texttt{BOOK} vs. \texttt{COOK} $\rightarrow$ 1 letter is different $\rightarrow$ Hamming distance = 1.
        \item \texttt{BOOK} vs. \texttt{BOLD} $\rightarrow$ 2 letters are different $\rightarrow$ Hamming distance = 2.
        \item \texttt{BOOK} vs. \texttt{WINE} $\rightarrow$ 4 letters are different $\rightarrow$ Hamming distance = 4.
    \end{itemize}

    \parhead{Why this matters for error detection}
    Imagine you can only use two words for your code: \texttt{CAT} and \texttt{DOG}. Their Hamming distance is 3.
    \begin{itemize}
        \item You send \texttt{CAT}.
        \item Noise corrupts one letter, and the receiver gets \texttt{COT}.
        \item The receiver checks its dictionary: Is \texttt{COT} closer to \texttt{CAT} (distance 1) or \texttt{DOG} (distance 2)? It's closer to \texttt{CAT}, so the error is automatically corrected.
    \end{itemize}
    This is the entire principle of error correction. By choosing a set of "valid" codewords that are far apart from each other, a receiver can detect and even correct errors by simply finding the closest valid codeword to what it received.

    \parhead{The golden rules}
    The \textbf{minimum Hamming distance} ($d_{\min}$) of a code determines its power:
    \begin{itemize}
        \item To \textbf{detect} up to $t$ errors, you need $d_{\min} \ge t+1$.
        \item To \textbf{correct} up to $t$ errors, you need $d_{\min} \ge 2t+1$.
    \end{itemize}
    This is why credit card numbers, ISBNs, and QR codes have built-in check digits---they are all designed to have a specific Hamming distance to catch common typos.
\end{nontechnical}


\subsection{Overview}

The \keyterm{Hamming distance} is a metric for comparing two binary strings of equal length. It is the number of bit positions in which the two strings differ. This simple concept, introduced by Richard Hamming in 1950, is the foundation of error control coding theory.

\begin{keyconcept}
    The \textbf{minimum Hamming distance ($d_{\min}$)} of a code---the smallest distance between any two valid codewords---is the single most important parameter that determines the code's error-handling capability. A code with minimum distance $d_{\min}$ can detect up to $d_{\min}-1$ errors and correct up to $\lfloor(d_{\min}-1)/2\rfloor$ errors.
\end{keyconcept}


\subsection{Mathematical Definitions}

\paragraph{Hamming Distance}
The Hamming distance, $d_H(x, y)$, between two codewords $x$ and $y$ is the number of positions where they differ. It is equivalent to the \keyterm{Hamming weight} (the number of non-zero elements) of their bitwise XOR.
\begin{equation}
    d_H(x, y) = w_H(x \oplus y)
\end{equation}

\paragraph{Minimum Distance ($d_{\min}$)}
The minimum distance of a code $C$ is the smallest Hamming distance between any pair of distinct codewords in the set. For \keyterm{linear codes}, this simplifies to the minimum weight of any non-zero codeword.
\begin{equation}
    d_{\min} = \min_{\substack{c_i, c_j \in C \\ i \neq j}} d_H(c_i, c_j) = \min_{\substack{c \in C \\ c \neq \mathbf{0}}} w_H(c)
\end{equation}

\paragraph{Error Detection and Correction Capability}
The power of a code is directly determined by its minimum distance.
\begin{itemize}
    \item \textbf{Error Detection:} A code can detect up to $t_d$ errors if $d_{\min} \ge t_d + 1$.
    \item \textbf{Error Correction:} A code can correct up to $t_c$ errors if $d_{\min} \ge 2t_c + 1$.
\end{itemize}
This can be visualised as surrounding each codeword with a "sphere" of a certain radius. For error correction, the spheres must not overlap.

\begin{table}[H]
    \centering
    \caption{Error Handling Capability vs. Minimum Distance}
    \label{tab:dmin-capability}
    \begin{tabular}{@{}ccc@{}}
        \toprule
        \tableheaderfont Minimum Distance ($d_{\min}$) & \tableheaderfont Detects up to... & \tableheaderfont Corrects up to... \\
        \midrule
        2 & 1 error & 0 errors \\
        3 & 2 errors & 1 error \\
        4 & 3 errors & 1 error (and detects 2) \\
        5 & 4 errors & 2 errors \\
        6 & 5 errors & 2 errors (and detects 3) \\
        7 & 6 errors & 3 errors \\
        \bottomrule
    \end{tabular}
\end{table}


\subsection{Common Error Detection Schemes}

\paragraph{Parity Check}
The simplest form of error detection. A single parity bit is added to a block of data to make the total number of '1's either even or odd.
\begin{itemize}
    \item \textbf{Minimum Distance:} $d_{\min} = 2$.
    \item \textbf{Capability:} Can detect any single-bit error (and any odd number of errors). It cannot detect an even number of errors and cannot correct any errors.
    \item \textbf{Application:} Serial communication (UART), simple memory checks.
\end{itemize}

\paragraph{Cyclic Redundancy Check (CRC)}
A powerful and efficient error-detecting code based on polynomial division. A fixed-length checksum (e.g., 32 bits for CRC-32) is generated for a block of data.
\begin{itemize}
    \item \textbf{Capability:} A CRC of degree $r$ can detect all burst errors of length $\le r$, all odd numbers of errors, and a very high percentage ($1-2^{-r}$) of all other errors.
    \item \textbf{Application:} The workhorse of data integrity in networking (Ethernet, WiFi) and file formats (ZIP, PNG). It is used for detection only; retransmission is required to correct the error.
\end{itemize}


\begin{workedexample}{ECC Memory Design}
    \parhead{Problem} Design an error control code for a 64-bit computer memory word that must be able to correct any single-bit error and detect any double-bit error (a SECDED code).
    
    \parhead{Analysis}
    \begin{derivationsteps}
        \step \textbf{Determine the required minimum distance.} To correct $t=1$ error and simultaneously detect $s=1$ additional error (for a total of 2 detected errors), we need:
        \[ d_{\min} \ge 2t + s + 1 = 2(1) + 1 + 1 = 4 \]
        
        \step \textbf{Determine the number of parity bits.} The \keyterm{Hamming bound} gives the minimum number of parity bits, $r$, required to correct $t$ errors for $k$ data bits: $2^r \ge \sum_{i=0}^{t} \binom{k+r}{i}$. For $t=1$, this simplifies to $2^r \ge k+r+1$.
        For $k=64$: $2^r \ge 64+r+1 = 65+r$.
        \begin{itemize}
            \item If $r=6$, $2^6 = 64$, which is not $\ge 71$.
            \item If $r=7$, $2^7 = 128$, which is $\ge 72$. So, 7 parity bits are needed for single-bit correction.
        \end{itemize}
        To increase the minimum distance from 3 (for single-error correction) to 4 (for SECDED), an additional overall parity bit is added.
        Total parity bits: $r = 7 + 1 = 8$.

        \step \textbf{Select the code.} The resulting code is an \textbf{Extended Hamming (72,64) code}. It takes 64 data bits, adds 8 parity bits, has a minimum distance of $d_{\min}=4$, and provides the required SECDED capability.
    \end{derivationsteps}
    
    \parhead{Interpretation} This exact (72,64) SECDED code is the industry standard for ECC memory used in servers and mission-critical systems. It provides robust protection against the most common type of memory error (single-bit flips caused by cosmic rays) with a modest overhead of 12.5\%.
\end{workedexample}


\begin{importantbox}[title={Further Reading}]
    Hamming distance is the foundational metric for the entire field of error control coding.
    \begin{description}
        \item[Forward Error Correction] (\Cref{ch:fec}) provides a high-level overview of the different coding strategies that are all fundamentally designed to maximise minimum distance.
        \item[Block Codes] (\Cref{ch:block-codes}) provides a deep dive into specific code constructions like Hamming and Reed-Solomon codes and their distance properties.
        \item[Bit Error Rate] (\Cref{ch:ber}) explores how a code's minimum distance translates into a tangible "coding gain" on the BER performance curve.
    \end{description}
\end{importantbox}