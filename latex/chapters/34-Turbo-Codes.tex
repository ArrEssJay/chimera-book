% ==============================================================================
% CHAPTER 34: Turbo Codes
% ==============================================================================

\chapter{Turbo Codes}
\label{ch:turbo-codes}

\begin{nontechnical}
    \textbf{Turbo codes are like having two experts solve a puzzle by exchanging clues.} When they were unveiled in 1993, their performance was so good—so close to the theoretical limit of what was thought possible—that the engineering community was left in stunned disbelief.

    \parhead{The "Turbo" principle: Iterative feedback}
    Imagine two decoders working on the same corrupted message.
    \begin{enumerate}[label=\arabic*.]
        \item \textbf{Decoder 1} makes its best guess. It's not perfect, but it generates a list of which bits it is "highly confident" about and which are "50/50 guesses".
        \item It passes its list of confidence scores (the "clues") to \textbf{Decoder 2}.
        \item \textbf{Decoder 2} uses these clues to improve its own decoding process. It now has more information to work with. It generates its own, more refined list of confidence scores.
        \item It passes its new clues back to \textbf{Decoder 1}.
    \end{enumerate}
    They repeat this process, iterating back and forth 5-10 times. With each iteration, their shared confidence grows until they converge on a near-perfect solution. This feedback loop is analogous to a turbocharger in an engine, hence the name "Turbo Codes".

    \parhead{The impact}
    Before 1993, the best error-correcting codes were still several decibels away from the theoretical "Shannon Limit". Turbo codes came within a fraction of a decibel. This breakthrough made it possible to achieve reliable communication at much lower signal-to-noise ratios, revolutionising mobile and satellite communications. They were the key enabling technology for the 3G and 4G cellular standards.
\end{nontechnical}


\section{Overview and Properties}

\subsection{Overview}

\keyterm{Turbo codes} are a class of high-performance forward error-correcting codes that achieve a performance remarkably close to the Shannon limit. They were the first practical codes to do so, and their introduction in 1993 marked a major turning point in coding theory.

The architecture of a turbo code consists of the \keyterm{parallel concatenation} of two relatively simple \keyterm{Recursive Systematic Convolutional (RSC)} codes, separated by a pseudo-random \keyterm{interleaver}. The true innovation, however, lies in the receiver, which uses an \keyterm{iterative decoding} algorithm. Two soft-input, soft-output (SISO) decoders exchange extrinsic information, progressively refining their estimates of the transmitted data over several iterations.

\begin{keyconcept}
    The iterative exchange of "soft" probabilistic information between decoders is the key to the extraordinary performance of turbo codes. This "turbo principle" allows the combined system to achieve a coding gain of 8-10 dB, enabling reliable communication at an $E_b/N_0$ of less than 1 dB, just a few tenths of a dB from the theoretical Shannon limit.
\end{keyconcept}


\subsection{Encoder Architecture}

A standard rate-1/3 turbo encoder consists of two RSC encoders and an interleaver.
\begin{itemize}
    \item The first encoder operates on the original data stream, producing one stream of parity bits ($p_1$).
    \item The interleaver scrambles the order of the original data bits.
    \item The second encoder operates on the interleaved data stream, producing a second, different stream of parity bits ($p_2$).
\end{itemize}
The final transmitted codeword consists of the original, uns-coded data (the "systematic" part), plus the two sets of parity bits: $\mathbf{c} = [\mathbf{d}, \mathbf{p}_1, \mathbf{p}_2]$. Higher code rates (e.g., 1/2, 3/4) are achieved by \keyterm{puncturing} (systematically deleting) some of the parity bits before transmission.


\subsection{Iterative Decoding}

The turbo decoder consists of two component decoders (typically using the \keyterm{BCJR algorithm}) that mirror the encoder structure. The decoding is an iterative process:
\begin{description}
    \item[Iteration 1] The first decoder uses the systematic data and the first set of parity bits to produce a set of soft outputs, or \keyterm{Log-Likelihood Ratios (LLRs)}, for each data bit. The "new" information it generated is called the \keyterm{extrinsic information}.
    \item[Feedback] This extrinsic information is interleaved and passed to the second decoder as \emph{a priori} information.
    \item[Iteration 2] The second decoder now has three sources of information: the systematic data, its own parity bits, and the extrinsic information from the first decoder. It uses all three to generate a much more reliable set of extrinsic LLRs.
    \item[Repeat] This information is then de-interleaved and fed back to the first decoder. The process repeats, typically for 4 to 10 iterations, with the reliability of the LLRs improving at each stage until the decoder converges on a final, hard-decision output.
\end{description}


\subsection{Performance and Applications}

Turbo codes offer exceptional performance, especially at low signal-to-noise ratios, but they exhibit an "error floor" at very high SNRs, where the BER stops improving. Their performance is also dependent on the size of the interleaver; larger blocks yield better performance but introduce more latency.

\begin{table}[H]
    \centering
    \caption{Key Applications of Turbo Codes}
    \label{tab:turbo-applications}
    \begin{tabular}{@{}ll@{}}
        \toprule
        \tableheaderfont Standard & \tableheaderfont Application \\
        \midrule
        UMTS (3G) & Mobile data channels \\
        LTE (4G) & Mobile data channels (PDSCH/PUSCH) \\
        CCSDS & Deep-space missions (e.g., Mars rovers) \\
        DVB-RCS & Satellite return channel links \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{warningbox}
    While revolutionary, turbo codes have been largely superseded in the newest standards (5G, WiFi 6) by \textbf{LDPC codes}. LDPC codes offer similar near-capacity performance but have a lower error floor and a more parallelisable decoding algorithm, making them better suited for very high throughput and low latency applications.
\end{warningbox}

\begin{workedexample}{Turbo Code Performance Gain}
    \parhead{Problem} Quantify the performance benefit of using a rate-1/2 turbo code in a communication link.
    \parhead{Scenario} A system requires a post-FEC BER of $10^{-5}$.
    \parhead{Analysis}
    \begin{derivationsteps}
        \step \textbf{Determine Uncoded Requirement.} To achieve a BER of $10^{-5}$ with uncoded BPSK or QPSK, a system requires an $E_b/N_0$ of approximately \textbf{9.6 dB}.
        \step \textbf{Determine Coded Requirement.} A typical rate-1/2 turbo code can achieve the same BER of $10^{-5}$ at an $E_b/N_0$ of approximately \textbf{0.7 dB}.
        \step \textbf{Calculate Coding Gain.}
        \[ \text{Coding Gain} = (\text{Required } E_b/N_0)_{\text{uncoded}} - (\text{Required } E_b/N_0)_{\text{coded}} \]
        \[ \text{Coding Gain} = 9.6 \text{ dB} - 0.7 \text{ dB} = \textbf{\qty{8.9}{dB}} \]
    \end{derivationsteps}
    \parhead{Interpretation} The turbo code provides a remarkable 8.9 dB of coding gain. This means the system can operate with nearly \textbf{eight times less power} than an uncoded system for the same performance. This massive power saving is what made turbo codes essential for power-limited systems like mobile phones and deep-space probes.
\end{workedexample}

\begin{importantbox}[title={Further Reading}]
    Turbo codes represent the pinnacle of convolutional coding theory and the dawn of modern, capacity-approaching codes.
    \begin{description}
        \item[Convolutional Codes] (\Cref{ch:convolutional-codes}) explains the RSC encoders and Viterbi-style decoding that form the building blocks of a turbo decoder.
        \item[LDPC Codes] (\Cref{ch:ldpc}) are the modern successor to turbo codes, offering a different approach to achieving near-capacity performance with advantages in parallelism and error floor.
        \item[Shannon's Channel Capacity] (\Cref{ch:shannon}) is the theoretical benchmark that turbo codes so famously approached, changing the landscape of what was considered possible in communications.
    \end{description}
\end{importantbox}
