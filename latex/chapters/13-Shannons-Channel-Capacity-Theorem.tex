% ==============================================================================
% CHAPTER 13: Shannon's Channel Capacity Theorem
% ==============================================================================

\chapter{Shannon's Channel Capacity Theorem}
\label{ch:shannon}

\begin{nontechnical}
    \textbf{Shannon's Channel Capacity Theorem is the "speed limit" for all communication.} It defines the absolute maximum rate at which information can be transmitted reliably over a noisy channel.

    \parhead{The simple idea}
    \begin{itemize}
        \item Every communication channel (a WiFi link, a satellite connection, a fiber optic cable) has a maximum theoretical capacity. This capacity is determined by two factors: its \textbf{bandwidth} (how wide the pipe is) and its \textbf{signal-to-noise ratio} (how clean the connection is).
        \item If you try to send data \textbf{below} this capacity limit, Shannon proved that a sufficiently clever error correction code exists that can make the transmission virtually error-free.
        \item If you try to send data \textbf{above} this limit, errors are inevitable, no matter how sophisticated your system is.
    \end{itemize}

    \parhead{Why it matters} Published in 1948, this theorem revolutionised engineering. It transformed the problem of communication from an impossible fight against noise into a solvable puzzle: how to design a system that gets as close as possible to the Shannon limit. Every modern communication system, from 5G to deep-space probes, is a testament to this 70-year quest.
\end{nontechnical}


\section{Overview and Properties}

\subsection{Overview}

Claude Shannon's 1948 paper, "A Mathematical Theory of Communication," established the theoretical foundation for the entire field of information theory. Its central result, the \keyterm{Shannon-Hartley theorem}, provides a formula for the capacity of an \keyterm{Additive White Gaussian Noise (AWGN)} channel.

\begin{keyconcept}
    For an AWGN channel with bandwidth $B$ and a linear signal-to-noise ratio SNR, the channel capacity $C$ is:
    \[ C = B \log_2(1 + \text{SNR}) \quad (\text{bits/second}) \]
    This formula represents an absolute, physical limit on reliable data transmission. It proves that error-free communication is theoretically possible at any rate $R < C$, but impossible for any rate $R > C$.
\end{keyconcept}


\subsection{The Shannon Limit and Spectral Efficiency}

By rearranging the capacity formula, we can define two other critical concepts.

\paragraph{Spectral Efficiency ($\eta$)}
The maximum achievable data rate per unit of bandwidth is the \keyterm{spectral efficiency}, measured in bits/s/Hz:
\begin{equation}
    \eta_{\max} = \frac{C}{B} = \log_2(1 + \text{SNR})
\end{equation}
This shows that capacity grows logarithmically with SNR. To double the spectral efficiency, one must approximately square the signal-to-noise ratio.

\paragraph{The Shannon Limit}
By expressing the formula in terms of $E_b/N_0$, we can find the absolute minimum energy required to send one bit of information reliably. In the limit of infinite bandwidth, this converges to a fundamental constant:
\begin{equation}
    \lim_{B \to \infty} \frac{E_b}{N_0} = \ln(2) \approx -1.59 \text{ dB}
\end{equation}
This is the \keyterm{Shannon Limit}. No system can achieve error-free communication at an $E_b/N_0$ below this value. Modern error-correction codes, like LDPC and Turbo codes, have been designed to operate remarkably close to this limit, often within a few tenths of a decibel.


\subsection{Power-Limited vs. Bandwidth-Limited Regimes}

The capacity formula dictates two different design philosophies depending on the operating SNR.

\begin{description}
    \item[Power-Limited Regime (Low SNR)] In systems where signal power is scarce (e.g., deep-space probes, satellite links), the SNR is low. Here, capacity is approximately linear with SNR ($C \propto \text{SNR}$). The design goal is to be as power-efficient as possible. This is achieved by using power-efficient modulations (BPSK/QPSK) and very strong, low-rate error correction codes.
    \item[Bandwidth-Limited Regime (High SNR)] In systems where bandwidth is scarce but power is plentiful (e.g., fiber optics, WiFi), the SNR is high. Here, capacity is approximately logarithmic with SNR ($C \propto \log_2(\text{SNR})$). The design goal is to be as spectrally-efficient as possible. This is achieved by using high-order modulation schemes (e.g., 64-QAM, 256-QAM) to pack the maximum number of bits into each Hz of bandwidth.
\end{description}


\begin{workedexample}{WiFi vs. Deep Space Capacity}
    \parhead{Problem} Compare the theoretical channel capacity of a typical WiFi link and a deep-space link.
    
    \parhead{Case 1: WiFi Link (Bandwidth-Limited)}
    \begin{itemize}
        \item Bandwidth ($B$): \qty{20}{MHz}
        \item Signal-to-Noise Ratio (SNR): \qty{30}{dB} (linear ratio of 1000)
    \end{itemize}
    \[ C = B \log_2(1 + \text{SNR}) = (20 \times 10^6) \cdot \log_2(1001) \approx (20 \times 10^6) \cdot 9.97 \approx \textbf{\qty{199.4}{Mbps}} \]
    The high SNR allows for a very high spectral efficiency of nearly 10 bps/Hz.

    \parhead{Case 2: Deep Space Link (Power-Limited)}
    \begin{itemize}
        \item Bandwidth ($B$): \qty{1}{MHz}
        \item Signal-to-Noise Ratio (SNR): \qty{-10}{dB} (linear ratio of 0.1)
    \end{itemize}
    \[ C = B \log_2(1 + \text{SNR}) = (1 \times 10^6) \cdot \log_2(1.1) \approx (1 \times 10^6) \cdot 0.1375 \approx \textbf{\qty{137.5}{kbps}} \]
    \parhead{Interpretation} Even when the noise is ten times stronger than the signal (SNR = -10 dB), Shannon's theorem guarantees that reliable communication is still possible, up to a rate of 137.5 kbps. Achieving this, however, requires extremely powerful error-correction coding.
\end{workedexample}

\begin{table}[H]
    \centering
    \caption{Achieved Performance vs. Shannon Limit for Modern Systems}
    \label{tab:shannon-gap}
    \begin{tabular}{@{}lccc@{}}
        \toprule
        \tableheaderfont System & \tableheaderfont Typical SNR & \tableheaderfont Achieved $\eta$ (bps/Hz) & \tableheaderfont \% of Shannon Capacity \\
        \midrule
        GSM (2G Cellular) & 12 dB & 0.5 & $\sim$30\% \\
        WiFi 5 (802.11ac) & 25 dB & 6.0 & $\sim$75\% \\
        5G NR & 30 dB & 7.5 & $\sim$90\% \\
        DVB-S2X (Satellite) & Variable & Adaptive & >95\% \\
        \bottomrule
    \end{tabular}
\end{table}


\begin{importantbox}[title={Further Reading}]
    Shannon's theorem is the theoretical sun around which all other concepts in digital communications orbit.
    \begin{description}
        \item[Energy Ratios ($E_b/N_0$)] (\Cref{ch:energy-ratios}) provides the framework for understanding the ultimate -1.59 dB limit on power efficiency.
        \item[Forward Error Correction] (\Cref{ch:fec}) describes the practical coding techniques (LDPC, Turbo, Polar codes) that have been developed over 70 years to approach the Shannon limit.
        \item[Modulation Schemes] (\Cref{ch:qam}) like high-order QAM are a direct result of system designers trying to maximize spectral efficiency in the bandwidth-limited regime of the capacity curve.
    \end{description}
\end{importantbox}
